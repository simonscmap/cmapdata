<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Workflow &mdash; cmapdata 0.1.0 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/style.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=01f34227"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Table Creation and Indexing" href="indexing_strategies.html" />
    <link rel="prev" title="Web Validator" href="web_validator.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            cmapdata
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/installation.html">Installation and Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/database_design.html">Database Design and Table Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/compute_and_storage.html">Compute Resources and Data Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/pitfalls.html">Pitfalls</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Dataset Ingestion Examples</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="web_validator.html">Web Validator</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Workflow</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#user-submitted-datasets">User Submitted Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#outside-small-datasets">Outside ‘Small’ Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#outside-large-datasets">Outside ‘Large’ Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#metadata-updates">Metadata Updates</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="indexing_strategies.html">Table Creation and Indexing</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_validation.html">Data Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="continuous_ingestion.html">Continuous Ingestion</a></li>
<li class="toctree-l1"><a class="reference internal" href="gallery_examples/user_submitted_dataset_walkthrough.html">User Submitted Dataset Walkthrough</a></li>
<li class="toctree-l1"><a class="reference internal" href="gallery_examples/outside_small_dataset_walkthrough.html">Outside Small Dataset Walkthrough</a></li>
<li class="toctree-l1"><a class="reference internal" href="gallery_examples/outside_large_dataset_walkthrough.html">Outside Large Dataset Walkthrough</a></li>
<li class="toctree-l1"><a class="reference internal" href="gallery_examples/geotraces_walkthrough.html">Geotraces Seawater Walkthrough</a></li>
<li class="toctree-l1"><a class="reference internal" href="gallery_examples/eddy_walkthrough.html">Mesoscale Eddy Data Walkthrough</a></li>
<li class="toctree-l1"><a class="reference internal" href="gallery_examples/cruise_ingestion.html">Ingesting Cruise Metdata and Trajectory</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../subpackages/DB.html">DB</a></li>
<li class="toctree-l1"><a class="reference internal" href="../subpackages/collect.html">collect</a></li>
<li class="toctree-l1"><a class="reference internal" href="../subpackages/process.html">process</a></li>
<li class="toctree-l1"><a class="reference internal" href="../subpackages/ingest.html">ingest</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Future Improvements</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../future/code_changes.html">Code Changes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Ref</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../API/API_common.html">API Ref common.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../API/API_cruise.html">API Ref cruise.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../API/API_data.html">API Ref data.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../API/API_DB.html">API Ref DB.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../API/API_general.html">API Ref general.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../API/API_mapping.html">API Ref mapping.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../API/API_metadata.html">API Ref metadata.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../API/API_region_classifcation.html">API/API_region_classification.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../API/API_SQL.html">API Ref SQL.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../API/API_stats.html">API Ref stats.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../API/API_transfer.html">API Ref transfer.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../API/API_vault_structure.html">API Ref vault_structure.py</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">cmapdata</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Workflow</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/data_ingestion/workflow.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="workflow">
<h1>Workflow<a class="headerlink" href="#workflow" title="Link to this heading"></a></h1>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Rainier is currently the production database and ‘source of truth’. If you want to test features, use Mariana or Rossby.</p>
</div>
<p>The process for ingesting datasets into CMAP differs based on a few factors.
The three main categories are <em>User Submitted Datasets</em>, <em>Outside ‘Small’ Datasets</em> and <em>Outside ‘Large’ Datasets</em>.
User submitted datasets that pass through the web validator must be &lt;150MB.
<em>Outside ‘Small’ Datasets</em> are datasets collected that are collected from an outside source that can generally fit in memory. An example would be an AMT or HOT dataset.
<em>Outside ‘Large’ Datasets</em> are datasets collected from an outside source that have multiple data files and cannot fit into memory. Examples are satellite data, model data or large insitu collections such as ARGO or GOSHIP.</p>
<section id="user-submitted-datasets">
<h2>User Submitted Datasets<a class="headerlink" href="#user-submitted-datasets" title="Link to this heading"></a></h2>
<p>User submitted datasets are submitted through the web validator. Once the QA/QC checks are completed and a DOI is received, the dataset can be ingested into CMAP. Details on the QC process can be found here: <a class="reference external" href="https://simonscmap.atlassian.net/browse/CMAP-621">https://simonscmap.atlassian.net/browse/CMAP-621</a>. An additional step of adding org_id and conversion_coefficient columns to the variable metadata sheet in the submitted template is done only for variables describing organism abundance.</p>
<p>Using general.py, you can pass command line arguments to specify which server you wish to add the dataset to as well as including a DOI.</p>
<p>Where we have:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">general</span><span class="o">.</span><span class="n">py</span> <span class="p">{</span><span class="n">table_name</span><span class="p">}</span> <span class="p">{</span><span class="n">branch</span><span class="p">}</span> <span class="p">{</span><span class="n">filename</span><span class="p">}</span> <span class="p">{</span><span class="o">-</span><span class="n">d</span><span class="p">}</span> <span class="p">{</span><span class="n">DOI</span> <span class="n">link</span><span class="p">}</span> <span class="p">{</span><span class="o">-</span><span class="n">l</span><span class="p">}</span> <span class="p">{</span><span class="n">DOI</span> <span class="n">download</span> <span class="n">link</span><span class="p">}</span> <span class="p">{</span><span class="o">-</span><span class="n">f</span><span class="p">}</span> <span class="p">{</span><span class="n">DOI</span> <span class="n">file</span> <span class="n">name</span><span class="p">}</span> <span class="p">{</span><span class="o">-</span><span class="n">S</span><span class="p">}</span> <span class="p">{</span><span class="n">server</span><span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p>{<strong>table_name</strong>}: Table name for the dataset. Must start with prefix “tbl”. Ex. tblFalkor_2018</p></li>
<li><p>{<strong>branch</strong>}: Branch where dataset should be placed in Vault. Ex’s: cruise, float, station, satellite, model, assimilation</p></li>
<li><p>{<strong>filename</strong>}: Base file name in vault/staging/combined/. Ex.: ‘global_diazotroph_nifH.xlsx’</p></li>
<li><p>{<strong>-d</strong>}: Optional flag for including DOI with dataset in tblReferences. DOI link string follows flag arg.</p></li>
<li><p>{<strong>DOI link</strong>}: String for full web address of CMAP specific DOI. Ex. “<a class="reference external" href="https://doi.org/10.5281/zenodo.8306724">https://doi.org/10.5281/zenodo.8306724</a>”</p></li>
<li><p>{<strong>-l</strong>}: Optional flag for including the DOI download link in tblDataset_DOI_Download. DOI dowload link string follows flag.</p></li>
<li><p>{<strong>DOI download link</strong>}: String for DOI download link of CMAP specific DOI. Ex. “<a class="reference external" href="https://zenodo.org/record/8306724/files/Gradients5_TN412_LISST_DEEP_Profiles.xlsx?download=1">https://zenodo.org/record/8306724/files/Gradients5_TN412_LISST_DEEP_Profiles.xlsx?download=1</a>”</p></li>
<li><p>{<strong>-f</strong>}:  Optional flag for DOI file name. DOI file name string follows flag.</p></li>
<li><p>{<strong>DOI file name</strong>}:  String for filename of CMAP specific DOI. Ex. “Gradients5_TN412_LISST_DEEP_Profiles.xlsx”</p></li>
<li><p>{<strong>-t</strong>}: Optional flag for denoting if DOI is a web validator template. Default value is 1.</p></li>
<li><p>{<strong>DOI in CMAP template</strong>}:  Boolean if DOI is a web validator template.</p></li>
<li><p>{<strong>-S</strong>}: Required flag for specifying server choice. Server name string follows flag.</p></li>
<li><p>{<strong>server</strong>}: Valid server name string.  Ex. “Rainier”, “Mariana” or “Rossby”</p></li>
</ul>
<p>An example string would be:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">general</span><span class="o">.</span><span class="n">py</span> <span class="n">tblTN412_Gradients5_LISST_DEEP_Profiles</span> <span class="n">cruise</span> <span class="s1">&#39;Gradients5_TN412_LISST_DEEP_Profiles.xlsx&#39;</span> <span class="o">-</span><span class="n">S</span> <span class="s1">&#39;Rossby&#39;</span> <span class="o">-</span><span class="n">d</span> <span class="s1">&#39;https://doi.org/10.5281/zenodo.8306724&#39;</span> <span class="o">-</span><span class="n">l</span> <span class="s1">&#39;https://zenodo.org/record/8306724/files/Gradients5_TN412_LISST_DEEP_Profiles.xlsx?download=1&#39;</span> <span class="o">-</span><span class="n">f</span> <span class="s1">&#39;Gradients5_TN412_LISST_DEEP_Profiles.xlsx&#39;</span>
</pre></div>
</div>
<p>general.py contains wrapper functions that will split the excel sheet into pandas dataframes, transfer the data to vault/, build a suggested SQL table, insert data, split dataset_meta_data and vars_meta_data into SQL queries and insert into SQL metadata tables, build summary statistics, match provided cruises to cruises in the database, classify the dataset into ocean regions and create maps and icons for the web catalog.</p>
<p>Certain functions are only run when the server name is Rainier (creating icon map, data server alias assignment, and data ingestion tests). A suggested order for server ingestion is starting with Rossby (the fastest server), then ingesting to Mariana, and finally on Rainier. As DOIs are requirements for user submitted datasets, a function to test the data in the DOI matches the data in Rainier also runs automatically.</p>
</section>
<section id="outside-small-datasets">
<h2>Outside ‘Small’ Datasets<a class="headerlink" href="#outside-small-datasets" title="Link to this heading"></a></h2>
<p>These datasets usually need quite a bit of data munging to make them match the CMAP data format. Additionally, metadata needs to be collected and created.
To keep a record of data transformations, any processing scripts should be placed in <strong>/process/../process_datasetname.py</strong>. Additionally, any relevant collection information should be placed in <strong>/collect/../collect_datasetname.py</strong>. A text file containing a link to the process and collect scripts in GitHub should be saved in the vault to <strong>{dataset table name}/code/</strong></p>
<p>With the addition of the QC API, it is suggested to submit the final, cleaned dataset to the validator. Once QC is complete and the /final folder is populated with the finalized template, ingestion can be done as if it was a user submitted dataset as described above.</p>
</section>
<section id="outside-large-datasets">
<h2>Outside ‘Large’ Datasets<a class="headerlink" href="#outside-large-datasets" title="Link to this heading"></a></h2>
<p>These datasets are usually composed of multiple data files (generally in netcdf or hdf5). Some features of the ingestion pipeline only work for data that can fit into memory. Because of this, special care is needed to ingest these large datasets.
All raw data should be saved in the vault /raw folder for the dataset. Depending on the source, data is downloaded using curl/wget/ftp etc. Any collection scripts should be stored in <strong>/collect/../{collect_datasetname.py}.
Once data has been transfered, the next step is any data processing. This should be recorded in **/process/../process_datasetname.py</strong>. A text file containing a link to the process and collect scripts in GitHub should be saved in the vault to <strong>{dataset table name}/code/</strong></p>
<p>In this data processing script, data should be read from the vault /raw folder, cleaned, sorted and inserted into the database(s).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You will need to create a SQL table and add it to the databases prior to ingestion. Any SQL table creation script should be recorded in DB/ (repository is on Simons CMAP github). Adding indexes once the ingestion has completed will likely speed up ingestion.</p>
</div>
<p>After the data has been inserted and the indices successfully created, metadata will need to be created and added to the databases. A standard excel template should be used for the dataset and vars metadata sheets. Submit a template to the validator with a dummy data sheet that holds all variables, but only needs one row of data to make it through the validator. This allows the data curation team to run the QC API checks and create the /final folder needed for ingesting the metadata.</p>
<p>There are additional arguments you can use for large datasets:</p>
<ul class="simple">
<li><p>{<strong>-a</strong>}: Optional flag for specifying server name where data is located</p></li>
<li><p>{<strong>data_server</strong>}: Valid server name string.  Ex. “Rainier”, “Mariana”, “Rossby”, or “Cluster”</p></li>
<li><p>{<strong>-i</strong>}: Optional flag for specifying icon name instead of creating a map thumbnail of the data</p></li>
<li><p>{<strong>icon_filename</strong>}: Filename for icon in Github instead of creating a map thumbnail of data. Ex: argo_small.jpg</p></li>
<li><p>{<strong>-p</strong>}: Optional flag for defining process level</p></li>
<li><p>{<strong>process_level</strong>}: Default value is “rep”. Change to “nrt” for near-real-time datasets</p></li>
<li><p>{<strong>-F</strong>}: Optional flag for specifying a dataset has a valid depth column. Default value is 0</p></li>
<li><p>{<strong>-N</strong>}: Optional flag for specifying a ‘dataless’ ingestion or a metadata only ingestion</p></li>
</ul>
<p>The {-a} flag can be used if the data is not present on all on-prem servers (Rainier, Rossby, and Mariana), and has to be used if the data is only on the cluster. It can also help speed up the calculation of stats when ingesting metadata to Mariana or Rainier, if you use Rossby as the data_server. Rossby is the fastest on-prem server.</p>
<p>The {-i} flag is used if you want to display a logo instead of creating a map of the data for the thumbnail on the catalog page. The icon_filename needs to include the file extension, and should reference a logo or icon already saved in /static/mission_icons</p>
<p>The {-F} flag is needed when adding metadata that doesn’t include the full dataset in the excel template. When ingesting a template with data in it, the ingestion code checks for the presence of a depth field automatically. The depth flag is needed for the viz page to know which chart types to display. If a large dataset has a “depth” field (which should only be named as such if there are no rows with missing depth values), include <strong>-F 1</strong> in your ingestion command.</p>
</section>
<section id="metadata-updates">
<h2>Metadata Updates<a class="headerlink" href="#metadata-updates" title="Link to this heading"></a></h2>
<p>There are times when a dataset is already ingested, but updates to the metadata are needed. The <strong>-U</strong> argument will delete all metadata present for the dataset, but will retain the data table. The <strong>-F</strong> depth flag will need to be included if the dataset has depth. All flags related to a DOI will need to be included if the DOI link is not in the dataset_references column of the dataset_meta_data tab.</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Diana Haring.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>